# Llama RESTful Chatbot – Python Flask (Colab Demo)

## Overview

This project implements a simple RESTful chatbot API using the Llama language model and Flask in Python. The service accepts user messages via HTTP POST and returns responses generated by Llama. All code is provided in a Colab notebook for easy reproducibility.

***

## Features

- **Llama model via llama-cpp-python**
- *REST API with Flask* (/chat endpoint)
- *pyngrok support* for Colab-based public endpoint demo
- *Well-documented notebook*: code, API docs, testing, and troubleshooting
- *Sample curl/Postman requests* and error logs provided

***

## Quick Start

### 1. Run in Google Colab

- Open the notebook in Colab
- Run setup, install dependencies, and follow code cells

### 2. Test the REST API

POST requests to /chat:
bash
curl -X POST "http://YOUR_NGROK_URL/chat" \
     -H "Content-Type: application/json" \
     -d "{\"message\":\"What is Python?\"}"

- The ngrok URL is shown after starting Flask in Colab

***

## Troubleshooting

- Network/firewall/DNS issues may prevent public access to Colab/ngrok endpoint from some PCs.
- Sample error (Could not resolve host) and diagnostic screenshots are in this repo for transparency.
- Functionality is demonstrated in the notebook; code is ready for use on a VM or compatible server.

***

## Project Structure

- notebook.ipynb – Chatbot & REST API code, tests, outputs
- README.md – Project docs and usage notes
- selected_image_2236756640693574293.jpg – Example curl troubleshooting screenshot
